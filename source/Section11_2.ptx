<?xml version="1.0" encoding="UTF-8"?>
<section xml:id="Section11_2">
	<title>Revisiting Matrix Arithmetic</title>
	<idx><h>Matrices</h></idx>
	<idx><h>Matrix Arithmetic</h></idx>
	<introduction>
		<p>
			In this section we will review and expand upon what we learned about matrices and matrix arithmetic in <xref ref="chapter_7"/>.
		</p>
	</introduction>

	<subsection xml:id="ss-Add-Scalar-Multi-Matrices">
		<title>Addition and Scalar Multiplication of Matrices</title>
		<p>
			You have now solved systems of equations by writing them in terms of an augmented matrix
			and then doing row operations on this augmented matrix.
			It turns out such rectangular
			arrays of numbers are important from many other different points of view.
			Numbers are
			also called <term>scalars</term>.
			In this book, numbers will generally be either real or complex numbers.
			I will refer to the set of numbers as F sometimes when it is not important to worry about
			whether the number is real or complex.
			Thus F can be either the real numbers R or the
			complex numbers C.
			However, most of the algebraic considerations hold for more general
			fields of scalars.
		</p>

		<p>
			A <term>matrix</term> is a rectangular array of numbers.
			Several of them are referred to as <term>matrices</term>.
			For example, here is a matrix.
			<me>
				\left( \begin{array}{c c c c}
				1 &amp; 2 &amp; 3 &amp; 4 \\
				5 &amp; 2 &amp; 8 &amp; 7 \\
				6 &amp; -9 &amp; 1 &amp; 2\\
				\end{array} \right)
			</me>
			The size or dimension of a matrix is defined as <m>m \times n</m> where <m>m</m> is the number of rows and
			<m>n</m> is the number of columns.
			The above matrix is a <m>3 \times 4</m> matrix because there are three
			rows and four columns.
			The first row is <m>(1 \, 2 \, 3 \, 4)</m> , the second row is <m>(5 \, 2 \, 8 \, 7)</m> and so forth.
			The first column is <m>
			\left( \begin{array}{c}
			1 \\
			5 \\
			6 \\
			\end{array} \right)
			</m>.
			When specifying the size of a matrix, you always list the
			number of rows before the number of columns.
			Also, you can remember the columns are
			like columns in a Greek temple.
			They stand upright while the rows just lie there like rows
			made by a tractor in a plowed field.
			Elements of the matrix are identified according to
			position in the matrix.
			For example, 8 is in position 2, 3 because it is in the second row and
			the third column.
			You might remember that you always list the rows before the columns
			by using the phrase <em>Row</em>man <em>C</em>atholic.
			The symbol, <m>(a_{ij})</m> refers to a matrix.
			The entry in
			the <m>i^{th}</m> row and the <m>j^{th}</m> column of this matrix is denoted by <m>a_{ij}</m> .
			Using this notation on the
			above matrix, <m>a_{23} = 8, a_{32} = -9, a_{12} = 2,</m> etc.
		</p>

		<p>
			There are various operations which are done on matrices.
			Matrices can be added mul-
			tiplied by a scalar, and multiplied by other matrices.
			To illustrate scalar multiplication,
			consider the following example in which a matrix is being multiplied by the scalar 3.
			<me>
				3 \left( \begin{array}{c c c c}
				1 &amp; 2 &amp; 3 &amp; 4 \\
				5 &amp; 2 &amp; 8 &amp; 7 \\
				6 &amp; -9 &amp; 1 &amp; 2\\
				\end{array} \right) = \left( \begin{array}{c c c c}
				3 &amp; 6 &amp; 9 &amp; 12 \\
				15 &amp; 6 &amp; 24 &amp; 21 \\
				18 &amp; -27 &amp; 3 &amp; 6\\
				\end{array} \right)
			</me>
			The new matrix is obtained by multiplying every entry of the original matrix by the given
			scalar.
			If <m>A</m> is an <m>m \times n</m> matrix, <m>-A</m> is defined to equal <m>(-1) A</m>.
		</p>

		<p>
			Two matrices must be the same size to be added.
			The sum of two matrices is a matrix
			which is obtained by adding the corresponding entries.
			Thus
			<me>
				\left( \begin{array}{c c}
				1 &amp; 2 \\
				3 &amp; 4 \\
				5 &amp; 2\\
				\end{array} \right) +
				\left(\begin{array}{c c}
				-1 &amp; 4 \\
				2 &amp; 8 \\
				6 &amp; -4\\
				\end{array} \right) =
				\left(\begin{array}{c c }
				0 &amp; 6 \\
				5 &amp; 12 \\
				11 &amp; -2\\
				\end{array} \right)
			</me>
			Two matrices are equal exactly when they are the same size and the corresponding entries
			are identical.
			Thus
			<me>
				\left( \begin{array}{c c}
				0 &amp; 0 \\
				0 &amp; 0 \\
				0 &amp; 0\\
				\end{array} \right) \neq
				\left( \begin{array}{c c}
				0 &amp; 0 \\
				0 &amp; 0 \\
				\end{array} \right)
			</me>
			because they are different sizes.
			As noted above, you write <m>(c_{ij})</m> for the matrix <m>C</m> whose
			<m>ij^{th}</m> entry is <m>c_{ij}</m> .
			In doing arithmetic with matrices you must define what happens in terms
			of the <m>c_{ij}</m>  sometimes called the <term>entries</term> of the matrix or the <term>components</term> of the matrix.
		</p>

		<p>
			The above discussion stated for general matrices is given in the following definition.
		</p>

		<definition xml:id="def-scalar-matrix-mult">
			<title>Scalar Matrix Multiplication</title>
			<idx>
			<h>Scalar Matrix Multiplication</h>
			</idx>

			<statement>
				<p>
					If <m>A = (a_{ij})</m> and <m>k</m> is a scalar, then <m>kA = (ka_{ij})</m>.
				</p>
			</statement>
		</definition>

		<example>
			<p>
				<me>
					7
					\left(\begin{array}{c c}
					2 &amp; 0 \\
					1 &amp; -4 \\
					\end{array} \right) =
					\left( \begin{array}{c c}
					14 &amp; 0 \\
					7 &amp; 28 \\
					\end{array} \right)
				</me>.
			</p>
		</example>

		<definition xml:id="def-lin-alg-matrix-addition">
			<title>Matrix Addition</title>
			<idx>
			<h>Matrix Addition</h>
			</idx>

			<statement>
				<p>
					If <m>A = (a_{ij})</m> and <m>B = (b_{ij})</m> are two <m>m \times n</m> matrices.
					Then <m>A+B =
					C</m> where
					<me>
						C = (c_{ij})
					</me>
					for <m>c_{ij} = a_{ij} + b_{ij}</m> .
				</p>
			</statement>
		</definition>

		<example>
			<me>
				\left( \begin{array}{c c c}
				1 &amp; 2 &amp; 3\\
				1 &amp; 0 &amp; 4 \\
				\end{array} \right) +
				\left(\begin{array}{c c c}
				5 &amp; 2 &amp; 3 \\
				-6 &amp; 2 &amp; 1\\
				\end{array} \right) =
				\left(\begin{array}{c c c}
				6 &amp; 4 &amp; 6 \\
				-5 &amp; 2 &amp; 5 \\
				\end{array} \right)
			</me>

			<p>
				To save on notation, we will often use <m>A_{ij}</m> to refer to the <m>ij^{th}</m> entry of matrix <m>A</m>.
			</p>
		</example>

		<definition xml:id="def-zero-matrix">
			<title>Zero Matrix</title>
			<idx>
			<h>Zero Matrix</h>
			</idx>

			<statement>
				<p>
					The <m>m \times n</m> zero matrix is the <m>m \times n</m> matrix having every
					entry equal to zero.
					It is denoted by 0.
				</p>
			</statement>
		</definition>

		<example>
			<p>
				The <m>2 \times 3</m> zero matrix is <m>\left( \begin{array}{c c c}
				0 &amp; 0 &amp; 0\\
				0 &amp; 0 &amp; 0 \\
				\end{array} \right)</m>.
			</p>
		</example>

		<definition xml:id="def-lin-alg-matrix-equality">
			<title>Matrix Equality</title>
			<idx>
			<h>Matrix Equality</h>
			</idx>

			<statement>
				<p>
					Let <m>A</m> and <m>B</m> be two matrices.
					Then <m>A = B</m> means
					that the two matrices are of the same size and for <m>A = (a_{ij})</m> and <m>B = (b_{ij})</m> , <m>a_{ij} = b_{ij} </m>for all
					<m>1 \leq i \leq m</m> and <m>1 \leq j \leq n</m>.
				</p>
			</statement>
		</definition>

		<p>
			The following properties of matrices can be easily verified.
			You should do so.
			These
			properties are called the vector space axioms.
			<ul>
				<li>
					<p>
						Commutative Law Of Addition.
						<me>
							A + B = B + A,
						</me>
					</p>
				</li>

				<li>
					<p>
						Associative Law for Addition.
						<me>
							(A + B) +C = A + (B +C) ,
						</me>
					</p>
				</li>

				<li>
					<p>
						Existence of an Additive Identity
						<me>
							A + 0 = A,
						</me>
					</p>
				</li>

				<li>
					<p>
						Existence of an Additive Inverse
						<me>
							A + (-A) = 0.
						</me>
					</p>
				</li>
			</ul>
		</p>

		<p>
			Also for <m>\alpha, \beta</m> scalars, the following additional properties hold.
			<ul>
				<li>
					<p>
						Distributive law over Matrix Addition.
						<me>
							\alpha (A + B) = \alpha A + \alpha B,
						</me>
					</p>
				</li>

				<li>
					<p>
						Distributive law over Scalar Addition
						<me>
							(\alpha + \beta ) A = \alpha A + \beta A,
						</me>
					</p>
				</li>

				<li>
					<p>
						Associative law for Scalar Multiplication
						<me>
							\alpha (\beta A) = \alpha\beta (A) ,
						</me>
					</p>
				</li>

				<li>
					<p>
						Rule for Multiplication by 1.
						<me>
							1A = A.
						</me>
					</p>
				</li>
			</ul>
		</p>

		<p>
			As an example, consider the Commutative Law of Addition.
			Let <m>A + B = C</m> and <m>B + A =
			D</m>.
			Why is <m>D = C</m>?
			<me>
				C_{ij} = A_{ij} + B_{ij} = B_{ij} + A_{ij} = D_{ij} .
			</me>
			Therefore, <m>C = D</m> because the <m>ij^{th}</m> entries are the same.
			Note that the conclusion follows
			from the commutative law of addition of numbers.
		</p>
	</subsection>

	<subsection xml:id="subsec-mult-of-matrices">
		<title>Multiplication of Matrices</title>
		<p>
			This is where things get interesting.
			Matrices can be thought of as a rule for making new
			vectors from old vectors.
		</p>

		<definition xml:id="def-vectors">
			<title>Vectors</title>
			<idx>
			<h>Vector</h>
			</idx>

			<statement>
				<p>
					Matrices which are <m>n \times 1</m> or <m>1 \times n</m> are called <term>vectors</term> and are often denoted
					by a bold letter.
					Thus the <m>n \times 1</m> matrix
					<me>
						\mathbf{x} = \left( \begin{array}{c}
						x_1 \\
						\vdots \\
						x_n \\
						\end{array} \right)
					</me>
					is also called a <term>column vector</term>.
					The <m>1 \times n</m> matrix
					<me>
						\mathbf{x} = \left( \begin{array}{c c c}
						x_1 &amp; \dots &amp; x_n \\
						\end{array} \right)
					</me>
					is called a <term>row vector</term>.
				</p>
			</statement>
		</definition>

		<p>
			Although the following description of matrix multiplication may seem strange, it is in
			fact the most important and useful of the matrix operations.
			To begin with consider the
			case where a matrix is multiplied by a column vector.
			First consider a special case.
			<me>
				\left( \begin{array}{c c c}
				1 &amp; 2 &amp; 3\\
				4 &amp; 5 &amp; 6 \\
				\end{array} \right)
				\left(  \begin{array}{c}
				7 \\
				8 \\
				9\\
				\end{array} \right) = \mathord{?}
			</me>
			By definition, this equals
			<me>
				7 \left( \begin{array}{c}
				1\\
				4\\
				\end{array} \right) + 8 \left( \begin{array}{c}
				2\\
				5\\
				\end{array} \right) + 9 \left( \begin{array}{c}
				3\\
				6\\
				\end{array} \right) =
				\left( \begin{array}{c}
				50\\
				122\\
				\end{array} \right).
			</me>
		</p>

		<p>
			In more general terms,
			<md>
				<mrow> \begin{pmatrix}
				a_{11} &amp; a_{12}  &amp; a_{13} \\
				a_{21}  &amp; a_{22}  &amp; a_{23}  \\
				\end{pmatrix}
				\begin{pmatrix}
				x_1 \\
				x_2 \\
				x_3 \\
				\end{pmatrix} \amp  =
				x_1 \begin{pmatrix}
				a_{11}\\
				a_{21}\\
				\end{pmatrix}
				+ x_2 \begin{pmatrix}
				a_{12}\\
				a_{22} \\
				\end{pmatrix}
				+ x_3 \begin{pmatrix}
				a_{13}\\
				a_{23}\\
				\end{pmatrix} </mrow>
				<mrow> \amp =
				\begin{pmatrix}
				a_{11}x_1 + a_{12}x_2 + a_{13}x_3\\
				a_{21}x_1 + a_{22}x_2 + a_{23}x_3\\
				\end{pmatrix}.
				</mrow>
			</md>
			Thus you take <m>x_1</m> times the first column, add to <m>x_2</m> times the second column, and finally <m>x_3</m>
			times the third column.
			The above sum is called a <term>linear combination</term> of the given column
			vectors.
			These will be discussed more later.
			In general, a linear combination of vectors is
			just a sum consisting of scalars times vectors.
			When you multiply a matrix on the left by a
			vector on the right, the numbers making up the vector are just the scalars to be used in the
			linear combination of the columns as illustrated above.
		</p>

		<p>
			More generally, here is the definition of how to multiply an <m>(m \times n)</m> matrix times a
			<m>(n \times 1)</m> matrix (column vector).
		</p>

		<definition xml:id="def-matrix-vector-mult">
			<statement>
				<p>
					Let <m>A = A_{ij}</m> be an <m>m \times n</m> matrix and <m>\mathbf{v}</m> be an <m>n \times 1</m> matrix,
					<me>
						\mathbf{v} = \begin{pmatrix}
						v_1 \\
						\vdots\\
						v_n\\
						\end{pmatrix}, A = \begin{pmatrix}
						\mathbf{a}_1, \dots, \mathbf{a}_n \end{pmatrix}
					</me>
					where <m>\mathbf{a}_i</m> is an <m>m \times 1</m> column vector.
					Then <m>A\mathbf{v}</m> written as
					<me>
						\begin{pmatrix}
						\mathbf{a}_1, \dots, \mathbf{a}_n \end{pmatrix}
						\begin{pmatrix}
						v_1 \\
						\vdots\\
						v_n\\
						\end{pmatrix},
					</me>
					is the <m>m \times 1</m> column vector which equals the following linear combination of columns.
					<me>
						v_1 \mathbf{a}_1 + v_2 \mathbf{a}_2 + \dots + v_n\mathbf{a}_n \equiv \sum_{j=1}^n v_j\mathbf{a}_j
					</me>
					If the <m>j_{th}</m> column of <m>A</m> is
					<me>
						\begin{pmatrix}
						A_{1j} \\
						A_{2j} \\
						\vdots\\
						A_{mj}\\
						\end{pmatrix},
					</me>
					then the sum above takes the form
					<me>
						v_1\begin{pmatrix}
						A_{11} \\
						A_{21} \\
						\vdots\\
						A_{m1}\\
						\end{pmatrix} +
						v_2 \begin{pmatrix}
						A_{12} \\
						A_{22}\\
						\vdots\\
						A_{m2}\\
						\end{pmatrix}
						+ \dots + v_n\begin{pmatrix}
						A_{1n} \\
						A_{2n}\\
						\vdots\\
						A_{mn}\\
						\end{pmatrix}
					</me>
					Thus the <m>i_{th}</m> entry of <m>A\mathbf{v}</m> is <m>\sum_{j=1}^{n} A_{ij}v_j</m>.
					Note that multiplication by an <m>m \times n</m> matrix takes an
					<m>n \times 1</m> matrix, and produces an <m>m \times 1</m> matrix (vector).
				</p>
			</statement>
		</definition>

		<p>
			Here is another example.
		</p>

		<example>
			<p>
				Compute
				<me>
					\begin{pmatrix}
					1 &amp; 2 &amp; 1 &amp; 3\\
					0 &amp; 2 &amp; 1 &amp; -2\\
					2 &amp; 1 &amp; 4 &amp; 1\\
					\end{pmatrix}
					\begin{pmatrix}
					1 \\
					2\\
					0\\
					1\\
					\end{pmatrix}
				</me>
				First of all this is of the form <m>(3 \times 4) (4 \times 1)</m> and so the result should be a <m>(3 \times 1)</m> .
				Note how the inside numbers cancel.
				To get the element in the second row and first and only
				column, compute
				<md>
					<mrow>\sum_{k=1}^4 a_{2k}v_k \amp = a_{21}v_1 + a_{22}v_2 + a_{23}v_3 + a_{24}v_4 </mrow>
					<mrow> \amp = 0 \times 1 + 2 \times 2 + 1 \times 0 + (-2) \times 1 = 2.</mrow>
				</md>
				You should do the rest of the problem and verify
				<me>
					\begin{pmatrix}
					1 &amp; 2 &amp; 1 &amp; 3\\
					0 &amp; 2 &amp; 1 &amp; -2\\
					2 &amp; 1 &amp; 4 &amp; 1\\
					\end{pmatrix}
					\begin{pmatrix}
					1 \\
					2\\
					0\\
					1\\
					\end{pmatrix} =
					\begin{pmatrix}
					8 \\
					2\\
					5\\
					\end{pmatrix}
				</me>
			</p>
		</example>

		<p>
			The next task is to multiply an <m>m \times n</m> matrix times an <m>n \times p</m> matrix.
			Before doing so the following may be helpful.
		</p>

		<p>
			For <m>A</m> and  <m>B</m> matrices, in order to form the product, <m>AB</m>, the number of columns of <m>A</m> must equal the number of rows of <m>B</m>.
			Thus the form
			of the product must be
			<me>
				(m \times n)(n \times p) = m \times p.
			</me>
			Not the two outside numbers give the size of the product.
			Remember:
			<em>If the two middle numbers don't match, you can't multiply the matrices!</em>
		</p>

		<definition xml:id="def-conformable-matrices">
			<statement>
				<p>
					When the number of columns of <m>A</m> equals the number of rows of <m>B</m> the
					two matrices are said to be <term>conformable</term> and the product <m>AB</m> is obtained as follows.
					Let <m>A</m>
					be an <m>m \times n</m> matrix and let <m>B</m> be an <m>n \times p</m> matrix.
					Then <m>B</m> is of the form
					<me>
						B = (\mathbf{b}_1 , \dots , \mathbf{b}_p)
					</me>
					where <m>\mathbf{b}_k</m> is an <m>n \times 1</m> matrix or column vector.
					Then the <m>m \times p</m> matrix <m>AB</m> is defined as
					follows:
					<me>
						AB \equiv (A\mathbf{b}_1, \dots , A\mathbf{b}_p)
					</me>
					where <m>A\mathbf{b}_k</m> is an <m>m \times 1</m> matrix or column vector which gives the <m>k^{th}</m> column of <m>AB</m>.
				</p>
			</statement>
		</definition>

		<example>
			<p>
				Multiply the following:
				<me>
					\begin{pmatrix}
					1 &amp; 2 &amp; 1 \\
					0 &amp; 2 &amp; 1 \\
					\end{pmatrix}
					\begin{pmatrix}
					1 &amp; 2 &amp; 0\\
					0 &amp; 3 &amp; 1\\
					-2 &amp; 1 &amp; 1\\
					\end{pmatrix}
				</me>
			</p>

			<solution>
				<p>
					The first thing you need to check before doing anything else is whether it is possible
					to do the multiplication.
					The first matrix on left is a <m>2 \times 3</m> and the second matrix on right
					is a <m>3 \times 3</m>.
					Therefore, is it possible to multiply these matrices.
					According to the above
					discussion it should be a <m>2 \times 3</m> matrix of the form
					<me>
						\begin{pmatrix}
						\overbrace{
						\begin{pmatrix}
						1 &amp; 2 &amp; 1\\
						0 &amp; 2 &amp; 1\\
						\end{pmatrix}
						\begin{pmatrix}
						1 \\
						0\\
						-2\\
						\end{pmatrix}}^{\text{First column}}, &amp;
						\overbrace{
						\begin{pmatrix}
						1 &amp; 2 &amp; 1\\
						0 &amp; 2 &amp; 1\\
						\end{pmatrix}
						\begin{pmatrix}
						2 \\
						3\\
						1\\
						\end{pmatrix}}^{\text{Second column}}, &amp;
						\overbrace{
						\begin{pmatrix}
						1 &amp; 2 &amp; 1\\
						0 &amp; 2 &amp; 1\\
						\end{pmatrix}
						\begin{pmatrix}
						0 \\
						1\\
						1\\
						\end{pmatrix}}^{\text{Third column}}
						\end{pmatrix}
					</me>
					You know how to multiply a matrix times a vector and so you do so to obtain each of the three columns.
				</p>
			</solution>

			<answer>
				<p>
					<me>
						\begin{pmatrix}
						1 &amp; 2 &amp; 1\\
						0 &amp; 2 &amp; 1\\
						\end{pmatrix}
						\begin{pmatrix}
						1 &amp; 2 &amp; 0\\
						0 &amp; 3 &amp; 1\\
						-2 &amp; 1 &amp; 1\\
						\end{pmatrix} =
						\begin{pmatrix}
						-1 &amp; 9 &amp; 3 \\
						-2 &amp; 7 &amp; 3 \\
						\end{pmatrix}
					</me>
				</p>
			</answer>
		</example>

		<example>
			<p>
				Multiply the following,
				<me>
					\begin{pmatrix}
					1 &amp; 2 &amp; 0\\
					0 &amp; 3 &amp; 1\\
					-2 &amp; 1 &amp; 1\\
					\end{pmatrix}
					\begin{pmatrix}
					1 &amp; 2 &amp; 1 \\
					0 &amp; 2 &amp; 1 \\
					\end{pmatrix}
				</me>
			</p>

			<solution>
				<p>
					First check if it is possible.
					This is of the form <m>(3 \times 3) (2 \times 3) </m>.
					The inside numbers
					do not match and so you can't do this multiplication.
					This means that anything you write
					will be absolute nonsense because it is impossible to multiply these matrices in this order.
					Aren't they the same two matrices considered in the previous example? Yes they are.
					It is just that here they are in a different order.
					This shows something you must always
					remember about matrix multiplication.
					<em>Order Matters!
					Matrix Multiplication Is Not Commutative!</em>
					This is very different than multiplication of numbers!
				</p>
			</solution>
		</example>
	</subsection>

	<subsection xml:id="subsec-ijth-entry-of-matrix-prod">
		<title>The <m>ij^{th}</m> Entry of a Product</title>
		<p>
			It is important to describe matrix multiplication in terms of entries of the matrices.
			What is
			the <m>ij^{th}</m> entry of <m>AB</m>? It would be the <m>i^{th}</m> entry of the <m>j^{th}</m> column of <m>AB</m>.
			Thus it would be the
			<m>i^{th}</m> entry of <m>A\mathbf{b}_j</m> .
			Now
			<me>
				\mathbf{b}_j = \begin{pmatrix}
				B_{1j} \\
				\vdots\\
				B_{nj}\\
				\end{pmatrix}
			</me>
			and from the above defintion, the <m>i^{th}</m> entry is
			<me>
				\sum_{k=1}^{n} A_{ik}B_{kj} \equiv A_{i1}B_{1j} + A_{i2}B_{2j} + \dots + A_{in}B_{nj}
			</me>
			In terms of pictures of the matrix, you are doing
			<me>
				\begin{pmatrix}
				A_{11} &amp; A_{12}  &amp; \dots &amp; A_{1n} \\
				A_{21}  &amp; A_{22}  &amp; \dots &amp; A_{2n} \\
				\vdots &amp; \vdots &amp; &amp; \vdots\\
				A_{m1} &amp; A_{m2} &amp; \dots &amp; A_{mn}\\
				\end{pmatrix}
				\begin{pmatrix}
				B_{11} &amp; B_{12}  &amp; \dots &amp; B_{1p} \\
				B_{21}  &amp; B_{22}  &amp; \dots &amp; B_{2p} \\
				\vdots &amp; \vdots &amp; &amp; \vdots\\
				B_{n1} &amp; B_{n2} &amp; \dots &amp; B_{np}\\
				\end{pmatrix}
			</me>
			Then as explained above, the <m>j^{th}</m> column is of the form
			<me>
				\begin{pmatrix}
				A_{11} &amp; A_{12}  &amp; \dots &amp; A_{1n} \\
				A_{21}  &amp; A_{22}  &amp; \dots &amp; A_{2n} \\
				\vdots &amp; \vdots &amp; &amp; \vdots\\
				A_{m1} &amp; A_{m2} &amp; \dots &amp; A_{mn}\\
				\end{pmatrix}
				\begin{pmatrix}
				B_{1j}\\
				B_{2j} \\
				\vdots \\
				B_{nj}\\
				\end{pmatrix}
			</me>
			which is an <m>m \times 1</m> matrix or column vector which equals
			<me>
				\begin{pmatrix}
				A_{11}\\
				A_{21} \\
				\vdots \\
				A_{m1}\\
				\end{pmatrix}B_{1j} +
				\begin{pmatrix}
				A_{12}\\
				A_{22} \\
				\vdots \\
				A_{m2}\\
				\end{pmatrix}B_{2j} + \dots +
				\begin{pmatrix}
				A_{1n}\\
				A_{2n} \\
				\vdots \\
				A_{mn}\\
				\end{pmatrix}B_{nj}.
			</me>
			The second entry of this <m>m \times 1</m> matrix is
			<me>
				A_{21}B_{1j} + A_{22}B_{2j} + \dots + A_{2n}B_{nj} = \sum_{k=1}^{m} A_{2k}B_{kj}.
			</me>
			Similarly, the <m>i^{th}</m> entry of this <m>m \times 1</m> matrix is
			<me>
				A_{i1}B_{1j} + A_{i2}B_{2j} + \dots + A_{in}B_{nj} = \sum_{k=1}^{m} A_{ik}B_{kj}.
			</me>
			This shows the following definition for matrix multiplication in terms of the <m>ij^{th}</m> entries of the project
			coincides with <xref ref="def-conformable-matrices"/>
		</p>

		<definition xml:id="def-ijth-entry-of-matrix-prod">
			<statement>
				<p>
					Let <m>A = (A_{ij})</m> be an <m>m \times n</m> matrix and let <m>B = (B_{ij})</m> be an <m>n \times p</m> matrix.
					Then <m>AB</m> is an <m>m \times p</m> matrix and
					<me>
						\left(AB\right)_{ij} = \sum_{k=1}^{n} A_{ik}B_{kj} \equiv A_{i1}B_{1j} + A_{i2}B_{2j} + \dots + A_{in}B_{nj}
					</me>
					Another way to write this is
					<me>
						\left(AB\right)_{ij} = \overset{1 \times n} {\begin{pmatrix}
						A_{i1} &amp; A_{i2} &amp; \dots &amp; A_{in}\end{pmatrix}}
						\overset{n \times 1}{
						\begin{pmatrix}
						B_{1j} \\
						B_{2j} \\
						\vdots \\
						B_{nj}\end{pmatrix}}.
					</me>
					Note that to get <m>(AB)_{ij}</m> you multiply the <m>i^{th}</m> row of <m>A</m> and the <m>j^{th}</m> column of <m>B</m>.
					In terms of
					the dot product from calculus, the <m>ij^{th}</m> entry of <m>AB</m> is the dot product
					of the <m>i^{th}</m>  row of <m>A</m> with the <m>j^{th}</m> column of <m>B</m>.
				</p>
			</statement>
		</definition>

		<p>
			I will summarize the above discussion in the following
			proposition which shows that the above definition delivers the earlier one in <xref ref="def-conformable-matrices"/>
			about <m>AB = \begin{pmatrix} A\mathbf{b}_1 &amp; \dots &amp; A\mathbf{b}_p\end{pmatrix}</m>.
			It is important
			to realize these two definitions are equivalent.
		</p>


		<proposition xml:id="prop-kth-column-is-Abk">
			<statement>
				<p>
					Let <m>A</m> be an <m>m \times n</m> matrix.
					Let <m>B = \begin{pmatrix} \mathbf{b}_1 &amp; \dots &amp; \mathbf{b}_p\end{pmatrix}</m> where each <m>\mathbf{b}_k</m>
					is a column vector or <m>n \times 1</m> matrix so <m>B</m> is an <m>n \times p</m> matrix.
					Then <m>AB</m> is an <m>m \times p</m> matrix and
					<me>
						AB = \begin{pmatrix} A\mathbf{b}_1 &amp; \dots &amp; A\mathbf{b}_p\end{pmatrix}
					</me>
					so the <m>k^{th}</m> column of <m>AB</m> is just <m> A\mathbf{b}_k</m>.
				</p>
			</statement>


			<proof>
				<p>
					From the definition of multiplication of matrices, <m>(AB)_{ik} = \sum_{r} A_{ir}B_{rk}</m>.
					However,
					<me>
						\mathbf{b}_k = \begin{pmatrix}
						B_{1k} \\
						\vdots \\
						B_{nk}\end{pmatrix}
					</me>
					and so, from the way we multiply a matrix times a vector,
					<me>
						(A\mathbf{b}_k)_i = \sum_r A_{ir}(\mathbf{b}_k)_r = \sum_r A_{ir}B_{rk}.
					</me>
					Thus, the <m>i^{th}</m> entry from the top of <m>A\mathbf{b}_k</m> is the <m>i^{th}</m> entry in the <m>k^{th}</m> column of <m>AB</m> showing
					that indeed the claim is true.
					<m>\blacksquare</m>
				</p>
			</proof>
		</proposition>

		<example>
			<p>
				Multiply if possible <m>\begin{pmatrix}
				1 &amp; 2 \\
				3 &amp; 1\\
				2 &amp; 6\\
				\end{pmatrix}
				\begin{pmatrix}
				2 &amp; 3 &amp; 1\\
				7 &amp; 6 &amp; 2\\
				\end{pmatrix}</m>.
			</p>

			<solution>
				<p>
					First check to see if this is possible.
					It is of the form <m>(3 \times 2) (2 \times 3)</m> and since the inside
					numbers match, the two matrices are conformable and it is possible to do the multiplication.
					The result should be a <m>3 \times 3</m> matrix.
					The answer is of the form
					<me>
						\begin{pmatrix}
						\begin{pmatrix}
						1 &amp; 2\\
						3 &amp; 1\\
						2 &amp; 6\\
						\end{pmatrix}
						\begin{pmatrix}
						2 \\
						7\\
						\end{pmatrix}, &amp;
						\begin{pmatrix}
						1 &amp; 2\\
						3 &amp; 1\\
						2 &amp; 6\\
						\end{pmatrix}
						\begin{pmatrix}
						3 \\
						6\\
						\end{pmatrix}, &amp;
						\begin{pmatrix}
						1 &amp; 2\\
						3 &amp; 1\\
						2 &amp; 6\\
						\end{pmatrix}
						\begin{pmatrix}
						1\\
						2\\
						\end{pmatrix}
						\end{pmatrix}
					</me>
					where the commas separate the columns in the resulting product.
					Thus the above product equals
					<me>
						\begin{pmatrix}
						16 &amp; 15 &amp; 5\\
						13 &amp; 15 &amp; 5\\
						46 &amp; 42 &amp; 14\\
						\end{pmatrix},
					</me>a
					<m>3 \times 3</m> matrix as desired.
					In terms of the <m>ij^{th}</m> entries and the above definition, the entry in
					the third row and second column of the product should equal
					<me>
						\sum_k a_{3k}b{k2} = a_{31}b{12} + a_{32}b{22} = 2 \times 3 + 6 \times 6 = 42.
					</me>
				</p>
			</solution>
		</example>

		<p>
			You should try a few more such examples to verify the above definition in terms of the <m>ij^{th}</m> entries works for other entries.
		</p>

		<example>
			Multiply if possible <m>\begin{pmatrix}
			1 &amp; 2 \\
			3 &amp; 1\\
			2 &amp; 6\\
			\end{pmatrix}
			\begin{pmatrix}
			2 &amp; 3 &amp; 1\\
			7 &amp; 6 &amp; 2\\
			0 &amp; 0 &amp; 0\\
			\end{pmatrix}</m>.
			<solution>
				<p>
					This is not possible because it is of the form <m>(3 \times 2)(3 \times 3)</m> and the middle numbers don't match.
					In other words the two
					matrices are not conformable in the indicated order.
				</p>
			</solution>
		</example>

		<example>
			Multiply if possible <m>\begin{pmatrix}
			2 &amp; 3 &amp; 1\\
			7 &amp; 6 &amp; 2\\
			0 &amp; 0 &amp; 0\\
			\end{pmatrix}\begin{pmatrix}
			1 &amp; 2 \\
			3 &amp; 1\\
			2 &amp; 6\\
			\end{pmatrix}
			</m>.

			<solution>
				<p>
					This is possible because in this case it is of the form <m>(3 \times 3)(3 \times 2)</m> and the middle numbers do match so the matrices are conformable.
					When the multiplication is done it equals
					<me>
						\begin{pmatrix}
						13 &amp; 13 \\
						29 &amp; 32\\
						0 &amp; 0\\
						\end{pmatrix}.
					</me>
					Check this and be sure you come up with the same answer.
				</p>
			</solution>
		</example>

		<example>
			Multiply if possible <m>\begin{pmatrix}
			1\\
			2\\
			1\\
			\end{pmatrix}\begin{pmatrix}
			1 &amp; 2 &amp; 1 &amp; 0\\
			\end{pmatrix}
			</m>.

			<solution>
				<p>
					In this case it is of the form <m>(3 \times 1)(1 \times 4)</m>.
					The middle numbers match so you can do it.
					Verify
					<me>
						\begin{pmatrix}
						1\\
						2\\
						1\\
						\end{pmatrix}\begin{pmatrix}
						1 &amp; 2 &amp; 1 &amp; 0\\
						\end{pmatrix} = \begin{pmatrix}
						1 &amp; 2 &amp; 1 &amp; 0\\
						2 &amp; 4 &amp; 2 &amp; 0\\
						1 &amp; 2 &amp; 1 &amp; 0\\
						\end{pmatrix}.
					</me>
				</p>
			</solution>
		</example>
	</subsection>

	<subsection xml:id="subsec-props-of-matrix-mult">
		<title>Properties of Matrix Multiplication</title>
		<p>
			As pointed out above, sometimes it is possible to multiply matrices in one order but not
			in the other order.
			What if it makes sense to multiply them in either order? Will the two
			products be equal then?
		</p>

		<example>
			<p>
				Compare <m>\begin{pmatrix}
				1 &amp; 2\\
				3 &amp; 4\\
				\end{pmatrix}\begin{pmatrix}
				0 &amp; 1 \\
				1 &amp; 0\\
				\end{pmatrix}</m> and <m>\begin{pmatrix}
				0 &amp; 1 \\
				1 &amp; 0\\
				\end{pmatrix}\begin{pmatrix}
				1 &amp; 2\\
				3 &amp; 4\\
				\end{pmatrix}</m>
			</p>

			<p>
				The first product is
				<me>
					\begin{pmatrix}
					1 &amp; 2\\
					3 &amp; 4\\
					\end{pmatrix}\begin{pmatrix}
					0 &amp; 1 \\
					1 &amp; 0\\
					\end{pmatrix} = \begin{pmatrix}
					2 &amp; 1 \\
					4 &amp; 3\\
					\end{pmatrix}.
				</me>
			</p>

			<p>
				The second product is
				<me>
					\begin{pmatrix}
					0 &amp; 1 \\
					1 &amp; 0\\
					\end{pmatrix}
					\begin{pmatrix}
					1 &amp; 2\\
					3 &amp; 4\\
					\end{pmatrix} = \begin{pmatrix}
					3 &amp; 4 \\
					1 &amp; 2\\
					\end{pmatrix}.
				</me>
				You see these are not equal.
				Again you cannot conclude that <m>AB = BA</m> for matrix multiplication
				even when multiplication is defined in both orders.
				However, there are some
				properties which do hold.
			</p>
		</example>


		<proposition xml:id="prop-matrix-mult-distributivity">
			<statement>
				<p>
					If all multiplications and additions make sense, the following hold for
					matrices, <m>A, B, C</m> and <m>a, b</m> scalars.
					<mdn>
						<mrow xml:id="eq-mat-dist1">A(aB + bC) \amp = a(AB) + b(BC) </mrow>
						<mrow xml:id="eq-mat-dist2">(B + C)A \amp = BA + CA </mrow>
						<mrow xml:id="eq-mat-assoc">A(BC) \amp = (AB)C </mrow>
					</mdn>
				</p>
			</statement>


			<proof>
				<p>
					Using <xref ref="def-ijth-entry-of-matrix-prod"/>,
					<md>
						<mrow>(A(aB + bC))_{ij} \amp \sum_{k} A_{ik}(aB_{kj} + bC_{kj}) </mrow>
						<mrow> \amp  = a\sum_{k} A_{ik}B_{kj} + b\sum_{k} A_{ik}C_{kj}</mrow>
						<mrow> \amp = a(AB)_{ij} + b(AC)_{ij}</mrow>
						<mrow> \amp =  (a(AB) + b(BC))_{ij}.</mrow>
					</md>
					Thus <m>A(aB + bC) = a(AB) + b(BC)</m> as claimed.
					Formula <xref ref="eq-mat-dist2"/> is entirely similar.
				</p>

				<p>
					Formula <xref ref="eq-mat-assoc"/> is the associative law of multiplication.
					Using definition <xref ref="def-ijth-entry-of-matrix-prod"/>
					<md>
						<mrow>(A(BC))_{ij} \amp \sum_{k} A_{ik}(BC)_{kj} </mrow>
						<mrow> \amp \sum_{k} A_{ik} \sum_{l} B_{kl}C_{lj}</mrow>
						<mrow> \amp \sum_{l} (AB)_{il}C_{lj}</mrow>
						<mrow> \amp ((AB)C)_{ij}.</mrow>
					</md>
					This proves <xref ref="eq-mat-assoc"/>.
					<m>\blacksquare</m>
				</p>
			</proof>
		</proposition>
	</subsection>

	<subsection xml:id="subsec-matrix-transpose">
		<title>Matrix Transpose</title>
		<p>
			Another important operation on matrices is that of taking the <term>transpose</term>.
			The following
			example shows what is meant by this operation, denoted by placing a <m>T</m> as an exponent on
			the matrix.
			<me>
				\begin{pmatrix}
				1 &amp; 4\\
				3 &amp; 1\\
				2 &amp; 6\\
				\end{pmatrix}^{T} =
				\begin{pmatrix}
				1 &amp; 3 &amp; 2 \\
				4 &amp; 1 &amp; 6 \\
				\end{pmatrix}
			</me>
			What happened? The first column became the first row and the second column became the
			second row.
			Thus the <m>3 \times 2</m> matrix became a <m>2 \times 3</m> matrix.
			The number 3 was in the second
			row and the first column and it ended up in the first row and second column.
			Here is the
			definition.
		</p>

		<definition xml:id="def-matrix-transpose">
			<statement>
				<p>
					Let <m>A</m> be an <m>m \times n</m> matrix.
					Then <m>A^T</m> denotes the <m>n \times n</m> matrix which is defined as follows.
					<me>
						(A^T)_{ij} = A_{ji}
					</me>
				</p>
			</statement>
		</definition>

		<example>
			<me>
				\begin{pmatrix}
				1 &amp; 2 &amp; -6 \\
				3 &amp; 5 &amp; 4 \\
				\end{pmatrix}^{T} =
				\begin{pmatrix}
				1 &amp; 3\\
				2 &amp; 5\\
				-6 &amp; 4\\
				\end{pmatrix}
			</me>
		</example>

		<p>
			The transpose of a matrix has the following important properties.
			<lemma xml:id="lem-transpose-distributivity">
				<statement>
					<p>
						Let <m>A</m> be an <m>m \times n</m> matrix and let <m>B</m> be a <m>n \times p</m> matrix.
						Then
						<me>
							(AB)^T = B^T A^T
						</me>
						and if <m>\alpha</m> and <m>\beta</m> are scalars,
						<me>
							(\alpha A + \beta B)^T = \alpha A^T + \beta B^T
						</me>
					</p>
				</statement>


				<proof>
					<p>
						From the definition,
						<me>
							\begin{pmatrix}(AB)^T \end{pmatrix}_{ij} = (AB)_{ji} = \sum_k (B^T)_{ik}(A^T)_{kj} = (B^T A^T)_{ij}.
						</me>
						The proof of the second formula is left as an exercise.<m>\blacksquare</m>
					</p>
				</proof>
			</lemma>
		</p>

		<definition xml:id="def-symmetric-matrix">
			<statement>
				<p>
					An <m>n \times n</m> matrix <m>A</m> is said to be <term>symmetric</term> if <m>A = A^T</m> .
					It is said to be <term>skew
					symmetric</term> if <m>A = -A^T</m> .
				</p>
			</statement>
		</definition>

		<example>
			<p>
				Let
				<me>
					A = \begin{pmatrix}
					2 &amp; 1 &amp; 3\\
					1 &amp; 5 &amp; -3\\
					3 &amp; -3 &amp; 7.\\
					\end{pmatrix}
				</me>
				Then
				<me>
					A^T = \begin{pmatrix}
					2 &amp; 1 &amp; 3\\
					1 &amp; 5 &amp; -3\\
					3 &amp; -3 &amp; 7.\\
					\end{pmatrix}
				</me>
				Therefore, <m>A</m> is symmetric.
			</p>
		</example>

		<example>
			<p>
				Let
				<me>
					A = \begin{pmatrix}
					0 &amp; 1 &amp; 3\\
					-1 &amp; 0 &amp; 2\\
					-3 &amp; -2 &amp; 0.\\
					\end{pmatrix}
				</me>
				Then
				<me>
					A^T = \begin{pmatrix}
					0 &amp; -1 &amp; -3\\
					1 &amp; 0 &amp; -2\\
					3 &amp; 2 &amp; 0.\\
					\end{pmatrix}
				</me>
				Therefore, <m>A</m> is skew symmetric.
			</p>
		</example>
	</subsection>

	<subsection xml:id="subsec-identity-matrix">
		<title>Identity Matrix</title>
		<p>
			There is a special matrix called <m>I</m> and referred to as the identity matrix.
			It is always a square
			matrix, meaning the number of rows equals the number of columns and it has the property
			that there are ones down the main diagonal and zeroes elsewhere.
			Here are some identity
			matrices of various sizes.
			<me>
				\begin{pmatrix}
				1
				\end{pmatrix},
				\begin{pmatrix}
				1 &amp; 0\\
				0 &amp; 1
				\end{pmatrix},
				\begin{pmatrix}
				1 &amp; 0 &amp; 0\\
				0 &amp; 1 &amp; 0\\
				0 &amp; 0 &amp; 1\\
				\end{pmatrix},
				\begin{pmatrix}
				1 &amp; 0 &amp; 0 &amp; 0\\
				0 &amp; 1 &amp; 0 &amp; 0\\
				0 &amp; 0 &amp; 1 &amp; 0\\
				0 &amp; 0 &amp; 0 &amp; 1\\
				\end{pmatrix}
			</me>
			The first is the <m>1 \times 1</m> identity matrix, the second is the <m>2 \times 2</m> identity matrix, the third is the
			<m>3 \times 3</m> identity matrix, and the fourth is the <m>4 \times 4</m> identity matrix.
			By extension, you can
			likely see what the <m>n \times n</m> identity matrix would be.
			It is so important that there is a special
			symbol to denote the <m>ij^{th}</m> entry of the identity matrix <m>I_{ij} = \delta_{ij}</m> where <m>\delta_{ij}</m> is the <term>Kronecker
			symbol</term> defined by
			<me>
				\delta_{ij} = \begin{cases}
				1 &amp; \text{ if } i = j \\
				0 &amp; \text{ if } i \neq j\\
				\end{cases}
			</me>
			It is called the <term>identity matrix</term> because it is a <term>multiplicative identity</term> in the following
			sense.
			<lemma xml:id="lem-identity-matrix">
				<statement>
					<p>
						Suppose <m>A</m> is an <m>m \times n</m> matrix and <m>I_n</m> is the <m>n \times n</m> identity matrix.
						Then
						<m>AI_n = A</m>.
						If <m>I_m</m> is the <m>m \times m</m> identity matrix, it also follows that <m>I_m A = A</m>.
					</p>
				</statement>


				<proof>
					<p>
						<me>
							(AI_n)_{ij} = \sum_{k} A_{ik}\delta_{kj} = A_{ij}
						</me>
						and so <m>AI_n = A</m>.
						The other case is left as an exercise for you.
						<m>\blacksquare</m>
					</p>
				</proof>
			</lemma>
		</p>
	</subsection>

	<exercises xml:id="exercises-11-2">
	<title>Exercises</title>
	<exercise number="1">
		<statement>
			<p>
				Here are some matrices:
			</p>
			<me>
				A = \begin{pmatrix}
				1 &amp; 2 &amp; 3\\
				2 &amp; 1 &amp; 7
				\end{pmatrix},
				B =
				\begin{pmatrix}
				3 &amp; -1 &amp; 2\\
				-3 &amp; 2 &amp; 1
				\end{pmatrix},
			</me>
			<me>
				C = \begin{pmatrix}
				1 &amp; 2\\
				3 &amp; 1
				\end{pmatrix},
				D = \begin{pmatrix}
				-1 &amp; 2\\
				2 &amp; -3
				\end{pmatrix},
				E = \begin{pmatrix}
				2\\
				3
				\end{pmatrix}
			</me>

			<p>
				Find if possible <m>-3A, 3B - A, AC, CB, AE, EA.</m> If it is not possible explain why.
			</p>
		</statement>

		<answer>
			<me>
				-3A = \begin{pmatrix}
				-3 &amp; -6 &amp; -9\\
				-6 &amp; -3 &amp; -21
				\end{pmatrix}
			</me>
			<me>
				3B - A = \begin{pmatrix}
				9 &amp; -3 &amp; 6\\
				-9 &amp; 6 &amp; 3
				\end{pmatrix} - \begin{pmatrix}
				1 &amp; 2 &amp; 3\\
				2 &amp; 1 &amp; 7
				\end{pmatrix} =
				\begin{pmatrix}
				8 &amp; -5 &amp; 3\\
				-11 &amp; 5 &amp; -4
				\end{pmatrix}
			</me>
			<me>
				AC = \text{ not possible because } A \text{ has more rows than } C \text{ has columns.}
			</me>
			<me>
				CB = \begin{pmatrix}
				1 &amp; 2\\
				3 &amp; 1
				\end{pmatrix}\begin{pmatrix}
				3 &amp; -1 &amp; 2\\
				-3 &amp; 2 &amp; 1
				\end{pmatrix} = \begin{pmatrix}
				-3 &amp; 3 &amp; 4\\
				6 &amp; -1 &amp; 7
				\end{pmatrix}
			</me>
			<me>
				AE = \text{ not possible because } A \text{ has more rows than } E \text{ has columns.}
			</me>
			<me>
				EA = \text{ not possible because } E \text{ has less rows than } A \text{ has columns.}
			</me>
		</answer>
	</exercise>

	<exercise number="2">
		<statement>
			<p>
				Here are some matrices:
			</p>
			<me>
				A = \begin{pmatrix}
				1 &amp; 2\\
				3 &amp; 2 \\
				1 &amp; -1
				\end{pmatrix},
				B =
				\begin{pmatrix}
				2 &amp; -5 &amp; 2\\
				-3 &amp; 2 &amp; 1
				\end{pmatrix},
			</me>
			<me>
				C = \begin{pmatrix}
				1 &amp; 2\\
				5 &amp; 0
				\end{pmatrix},
				D = \begin{pmatrix}
				-1 &amp; 1\\
				4 &amp; -3
				\end{pmatrix},
				E = \begin{pmatrix}
				1\\
				3
				\end{pmatrix}
			</me>

			<p>
				Find if possible <m>-3A, 3B - A, AC, CA, AE, EA, BE, DE.</m> If it is not possible explain why.
			</p>
		</statement>
	</exercise>

	<exercise number="3">
		<statement>
			<p>
				Here are some matrices:
			</p>
			<me>
				A = \begin{pmatrix}
				1 &amp; 2 \\
				3 &amp; 2 \\
				1 &amp; -1
				\end{pmatrix},
				B =
				\begin{pmatrix}
				2 &amp; -5 &amp; 2\\
				-3 &amp; 2 &amp; 1
				\end{pmatrix},
			</me>
			<me>
				C = \begin{pmatrix}
				1 &amp; 2\\
				5 &amp; 0
				\end{pmatrix},
				D = \begin{pmatrix}
				-1 &amp; 1\\
				4 &amp; -3
				\end{pmatrix},
				E = \begin{pmatrix}
				1\\
				3
				\end{pmatrix}
			</me>

			<p>
				Find if possible <m>-3A^{T}, 3B - A^{T}, AC, CA, AE, E^{T}B, BE, DE, EE^{T}, E^{T}E.</m> If it is not possible explain why.
			</p>
		</statement>

		<answer>
			<me>
				-3A^{T} = \begin{pmatrix}
				-3 &amp; -6 \\
				-9 &amp; -6 \\
				-3 &amp;  3
				\end{pmatrix}^{T} = \begin{pmatrix}
				-3 &amp; -9 &amp; -3\\
				-6 &amp; -6 &amp; 3
				\end{pmatrix}
			</me>
			<me>
				3B - A^{T} = \begin{pmatrix}
				6 &amp; -15 &amp; 6\\
				-9 &amp; 6 &amp; 3
				\end{pmatrix} - \begin{pmatrix}
				1 &amp; 3 &amp; 1\\
				2 &amp; 2 &amp; -1
				\end{pmatrix} =
				\begin{pmatrix}
				8 &amp; -6 &amp; 5\\
				-7 &amp; 4 &amp; 4
				\end{pmatrix}
			</me>
			<me>
				AC = \ \begin{pmatrix}
				1 &amp; 2 \\
				3 &amp; 2 \\
				1 &amp; -1
				\end{pmatrix}\begin{pmatrix}
				1 &amp; 2\\
				5 &amp; 0
				\end{pmatrix} =
				\ \begin{pmatrix}
				11 &amp; 2 \\
				13 &amp; 6 \\
				-4 &amp; 2
				\end{pmatrix}
			</me>
			<me>
				CA = \text{ not possible because } C \text{ has less columns than } A \text{ has rows.}
			</me>
			<me>
				AE = \begin{pmatrix}
				1 &amp; 2 \\
				3 &amp; 2 \\
				1 &amp; -1
				\end{pmatrix}\begin{pmatrix}
				1\\
				3
				\end{pmatrix} = \begin{pmatrix}
				7\\
				9\\
				-2
				\end{pmatrix}
			</me>
			<me>
				E^{T}B =  \begin{pmatrix}
				1 &amp;3
				\end{pmatrix} \begin{pmatrix}
				2 &amp; -5 &amp; 2\\
				-3 &amp; 2 &amp; 1
				\end{pmatrix} =  \begin{pmatrix}
				-7 &amp; 1 &amp; 5
				\end{pmatrix}
			</me>
			<me>
				BE = \text{ not possible because } E \text{ has less rows than } B \text{ has columns.}
			</me>
			<me>
				DE = \begin{pmatrix}
				-1 &amp; 1\\
				4 &amp; -3
				\end{pmatrix}\begin{pmatrix}
				1\\
				3
				\end{pmatrix} = \begin{pmatrix}
				2\\
				-5
				\end{pmatrix}
			</me>
			<me>
				EE^{T} = \begin{pmatrix}
				1\\
				3
				\end{pmatrix} \begin{pmatrix}
				1 &amp; 3
				\end{pmatrix} =
				\begin{pmatrix}
				1 &amp; 3\\
				3 &amp; 9
				\end{pmatrix}
			</me>
			<me>
				E^{T}E = \begin{pmatrix}
				1 &amp; 3
				\end{pmatrix}
				\begin{pmatrix}
				1\\
				3
				\end{pmatrix} =
				\begin{pmatrix}
				10
				\end{pmatrix}
			</me>
		</answer>
	</exercise>

	<exercise number="4">
		<statement>
			<p>
				Here are some matrices:
			</p>
			<me>
				A = \begin{pmatrix}
				1 &amp; 2\\
				3 &amp; 2 \\
				1 &amp; -1
				\end{pmatrix},
				B =
				\begin{pmatrix}
				2 &amp; -5 &amp; 2\\
				-3 &amp; 2 &amp; 1
				\end{pmatrix},
			</me>
			<me>
				C = \begin{pmatrix}
				1 &amp; 2\\
				5 &amp; 0
				\end{pmatrix},
				D = \begin{pmatrix}
				-1\\
				4
				\end{pmatrix},
				E = \begin{pmatrix}
				1\\
				3
				\end{pmatrix}
			</me>

			<p>
				Find if possible <m>AD, DA, D^{T}B, D^{T}BE, E^{T}D, DE^{T} .</m> If it is not possible explain why.
			</p>
		</statement>
	</exercise>

	<exercise number="5">
		<statement>
			<p>
				Let
				<m>
				A = \begin{pmatrix}
				1 &amp; 1 \\
				-2 &amp; -1 \\
				1 &amp; 2
				\end{pmatrix},
				B =
				\begin{pmatrix}
				1 &amp; -1 &amp; -2\\
				2 &amp; 1 &amp;  -2
				\end{pmatrix},
				</m> and <m>C =
				\begin{pmatrix}
				1 &amp; 1 &amp; -3\\
				-1 &amp; 2 &amp;  0 \\
				-3 &amp; -1 &amp; 0
				\end{pmatrix}</m>
			</p>

			<p>Find if possible:
				<ol marker="(a)" cols="2">
					<li>
						<p>
							<m>AB</m>
						</p>
					</li>

					<li>
						<p>
							<m>BA</m>
						</p>
					</li>

					<li>
						<p>
							<m>AC</m>
						</p>
					</li>

					<li>
						<p>
							<m>CA</m>
						</p>
					</li>

					<li>
						<p>
							<m>CB</m>
						</p>
					</li>

					<li>
						<p>
							<m>BC</m>
						</p>
					</li>
				</ol>
				If not possible, explain why.
			</p>
		</statement>

		<answer>
			<p>
				<ol marker="(a)">
					<li>
						<p>
							<me>
								AB = \begin{pmatrix}
								1 &amp; 1 \\
								-2 &amp; -1 \\
								1 &amp; 2
								\end{pmatrix}
								\begin{pmatrix}
								1 &amp; -1 &amp; -2\\
								2 &amp; 1 &amp;  -2
								\end{pmatrix} =
								\begin{pmatrix}
								3 &amp; 0 &amp; -4 \\
								-4 &amp; 1 &amp; 6 \\
								5 &amp; 1 &amp; -6
								\end{pmatrix}
							</me>
						</p>
					</li>

					<li>
						<p>
							<me>
								BA =
								\begin{pmatrix}
								1 &amp; -1 &amp; -2\\
								2 &amp; 1 &amp;  -2
								\end{pmatrix} \begin{pmatrix}
								1 &amp; 1 \\
								-2 &amp; -1 \\
								1 &amp; 2
								\end{pmatrix} =
								\begin{pmatrix}
								-11 &amp; -8 \\
								4 &amp; -3
								\end{pmatrix}
							</me>
						</p>
					</li>

					<li>
						<p>
							<m>AC </m> is not possible, the number of columns of <m>A</m> do not match the number of rows of <m>C</m>.
						</p>
					</li>

					<li>
						<p>
							<me>
								CA=  \begin{pmatrix}
								1 &amp; 1 &amp; -3\\
								-1 &amp; 2 &amp;  0 \\
								-3 &amp; -1 &amp; 0
								\end{pmatrix}\begin{pmatrix}
								1 &amp; 1 \\
								-2 &amp; -1 \\
								1 &amp; 2
								\end{pmatrix} = \begin{pmatrix}
								-4 &amp; -4 \\
								-5 &amp; 1 \\
								-1 &amp; -4
								\end{pmatrix}
							</me>
						</p>
					</li>

					<li>
						<p>
							<m>CB</m> is not possible because the number of columns of <m>C</m> are not the same as the number of rows of <m>B</m>.
						</p>
					</li>

					<li>
						<p>
							<me>
								BC = \begin{pmatrix}
								1 &amp; -1 &amp; -2\\
								2 &amp; 1 &amp;  -2
								\end{pmatrix}
								\begin{pmatrix}
								1 &amp; 1 &amp; -3\\
								-1 &amp; 2 &amp;  0 \\
								-3 &amp; -1 &amp; 0
								\end{pmatrix} = \begin{pmatrix}
								8 &amp; 1 &amp; -3\\
								7 &amp; 6 &amp;  -6
								\end{pmatrix}
							</me>
						</p>
					</li>
				</ol>
			</p>
		</answer>
	</exercise>

	<exercise number="6">
		<statement>
			<p>
				Suppose <m>A</m> and <m>B</m> are square matrices of the same size.
				Which of the following are correct?
				<ol  marker="(a)" >
					<li>
						<p>
							<m>(A - B)^2 = A^2 - 2AB + B^2</m>
						</p>
					</li>

					<li>
						<p>
							<m>(AB)^2 = A^2 B^2</m>
						</p>
					</li>

					<li>
						<p>
							<m>(A + B)^2 = A^2 + 2AB + B^2</m>
						</p>
					</li>

					<li>
						<p>
							<m>(A + B)^2 = A^2 + AB + BA + B^2</m>
						</p>
					</li>

					<li>
						<p>
							<m>A^2 B^2 = A (AB) B</m>
						</p>
					</li>

					<li>
						<p>
							<m>(A + B)3 = A^3 + 3A^2 B + 3AB^2 + B^3</m>
						</p>
					</li>

					<li>
						<p>
							<m>(A + B) (A - B) = A^2 - B^2</m>
						</p>
					</li>
				</ol>
			</p>
		</statement>
	</exercise>

	<exercise number="7">
		<statement>
			<p>
				Let <m>A = \begin{pmatrix}
				-1 &amp; -1 \\
				3 &amp; 3
				\end{pmatrix}.</m>
				Find all <m>2 \times 2</m> matrices, <m>B</m> such that <m>AB = 0</m>.
			</p>
		</statement>

		<answer>
			<p>
				If <m>B</m> is all zeros then <m>AB = 0</m>:
				<me>
					\begin{pmatrix}
					-1 &amp; -1 \\
					3 &amp; 3
					\end{pmatrix}\begin{pmatrix}
					0 &amp; 0 \\
					0 &amp; 0
					\end{pmatrix} = \begin{pmatrix}
					0 &amp; 0 \\
					0 &amp; 0
					\end{pmatrix}
				</me>
			</p>

			<p>
				Otherwise let <m>B = \begin{pmatrix}
				x &amp; y \\
				z &amp; w
				\end{pmatrix}</m>, then <m>AB = 0</m> whenever <m>z = -x </m> and <m>w = -y</m>.
			</p>
		</answer>
	</exercise>

	<exercise number="8">
		<statement>
			<p>
				Let <m>\mathbf{x} = (-1, -1, 1)</m> and <m>\mathbf{y} = (0, 1, 2)</m> .
				Find <m>\mathbf{x^{T}y}</m> and <m>\mathbf{xy^{T}}</m> if possible.
			</p>
		</statement>
	</exercise>

	<exercise number="9">
		<statement>
			<p>
				Let <m>A = \begin{pmatrix}1 &amp; 2 \\
				3 &amp; 4
				\end{pmatrix}, B = \begin{pmatrix}
				1 &amp; 2 \\
				3 &amp; k
				\end{pmatrix} </m>.
				Is it possible to choose <m>k</m> such that <m>AB = BA</m>? If so, what should <m>k</m> equal?
			</p>
		</statement>

		<answer>
			<p>
				Yes, if <m>k = 4</m>, the matrices are identical so the order of multiplication doesn't matter, the outcome is the same.
			</p>
		</answer>
	</exercise>

	<exercise number="10">
		<statement>
			<p>
				Let <m>A = \begin{pmatrix}1 &amp; 2 \\
				3 &amp; 4
				\end{pmatrix}, B = \begin{pmatrix}
				1 &amp; 2 \\
				1 &amp; k
				\end{pmatrix} </m>.
				Is it possible to choose <m>k</m> such that <m>AB = BA</m>? If so, what should <m>k</m> equal?
			</p>
		</statement>
	</exercise>
	<!-- took some out from kuttler here about skew matrices and stuff-->
	<!--Kuttler ex 20-->
	<exercise number="11">
		<statement>
			<p>
				Prove that <m>I_{m}A = A</m> where <m>A</m> is an <m>m \times n</m> matrix.
			</p>
		</statement>

		<answer>
			<p>
				In matrix multiplication, the <m>i^{th}</m> row of the first matrix affects only the <m>i^{th}</m> row of the output.
				The <m>i^{th}</m> row of <m>I_m</m> is all 0s except for a 1 in the <m>i^{th}</m> column.
				Calculating the <m>i,k^{th}</m> element in the output matrix will be a sum of products of row <m>i</m> of <m>I_m</m> and
				column <m>k</m> of <m>A</m>.
				By definition these row and column vectors must be the same length.
				The products will all 0s,
				except for the <m>i^{th}</m> term, which will be <m>1 \cdot A_{ik}</m>.
				Therefore the <m>i,k^{th}</m> element in the output matrix will be
				identical to <m>A_{ik}</m>, so <m>I_{m}A = A.
				\blacksquare</m>
			</p>
		</answer>
	</exercise>

	<exercise number="12">
		<statement>
			<p>
				Give an example of matrices, <m>A, B, C </m> such that <m>B \neq C, A \neq 0,</m> and yet <m>AB = AC</m>.
			</p>
		</statement>
	</exercise>
	</exercises>
</section>
