<!DOCTYPE html>
<html lang="en-US">
<!--********************************************-->
<!--*       Generated from PreTeXt source      *-->
<!--*                                          *-->
<!--*         https://pretextbook.org          *-->
<!--*                                          *-->
<!--********************************************-->
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="robots" content="noindex, nofollow">
</head>
<body class="ignore-math">
<h4 class="heading"><span class="type">Paragraph</span></h4>
<div class="para">Of primary consideration when estimating an algorithm's performance is the number of <em class="emphasis">basic operations</em> required by the algorithm to process an input of a certain size. The terms "basic operations" and "size" are both rather vague and depend on the algorithm being analyzed. Size is often the number of inputs processed. For example, when singing <code class="code-inline tex2jax_ignore">BottlesOfBeer</code> the size of the input is the number of bottles of beer you start with. When comparing sorting algorithms the size of the problem is typically measured by the number of records to be sorted. A basic operation must have the property that its time to complete does not depend on the particular values of its operands. Adding or comparing two integer variables are examples of basic operations. Summing the contents of an array containing <span class="process-math">\(n\)</span> integers is not, because the cost depends on the value of <span class="process-math">\(n\)</span> (i.e., the size of the input).</div>
<span class="incontext"><a href="section9_3-AlgorthmicComplexity.html#p-2838" class="internal">in-context</a></span>
</body>
</html>
